{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Part 1: Data Preprocessing\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Merge the Data\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Import necessary packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import re\n",
    "import os, fnmatch\n",
    "import zipfile\n",
    "from datetime import datetime, timedelta\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Create Helpers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def walklevel(some_dir, level=0):\n",
    "    some_dir = some_dir.rstrip(os.path.sep)\n",
    "    assert os.path.isdir(some_dir)\n",
    "    num_sep = some_dir.count(os.path.sep)\n",
    "    for root, dirs, files in os.walk(some_dir):\n",
    "        yield root, dirs, files\n",
    "        num_sep_this = root.count(os.path.sep)\n",
    "        if num_sep + level <= num_sep_this:\n",
    "            del dirs[:]\n",
    "            \n",
    "def swap_day_month(s):\n",
    "    day, month, yr = s.split('.')\n",
    "    return month +'/' + day +'/' + yr\n",
    "\n",
    "def swap_day_month2(s):\n",
    "    yr, month, day = s.split('-')\n",
    "    return month +'/' + day +'/' + yr\n",
    "\n",
    "def create_hr_seq():\n",
    "    now = datetime(2000, 1, 1, 0, 0, 0)\n",
    "    last = datetime(2000, 1, 2, 0, 0, 0)\n",
    "    delta = timedelta(seconds=1)\n",
    "    times = []\n",
    "    while now < last:\n",
    "        times.append(repr(now.strftime('%H:%M:%S')))\n",
    "        now += delta\n",
    "    return times\n",
    "\n",
    "def create_dtype_dict():\n",
    "    dic = {}\n",
    "    dic['Unnamed: 0'] = str\n",
    "    for i in create_hr_seq():\n",
    "        dic[i] = float\n",
    "    return dic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Iterate through each house:\n",
    "  - Create a master DataFrame;\n",
    "  - Process *occupancy* data:\n",
    "    -\n",
    "  - Process *plugs* data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "%cd%\r\n"
     ]
    }
   ],
   "source": [
    "!echo %cd% # under windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-e7e795d7e7e0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mchange_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mDIR\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mCUR_PATH\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'/'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mDIR\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdirs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfiles\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mwalklevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCUR_PATH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0;31m### 6 Houses\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mhouse\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdirs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-600ab55e4992>\u001b[0m in \u001b[0;36mwalklevel\u001b[0;34m(some_dir, level)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mwalklevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msome_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0msome_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msome_dir\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0;32massert\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msome_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mnum_sep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msome_dir\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdirs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfiles\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwalk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msome_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "### master DataFrames of each house\n",
    "house_df_dict = {}\n",
    "\n",
    "CUR_PATH = '~/Desktop/IEOR135/DataSets'\n",
    "change_path = lambda DIR : CUR_PATH + '/' + DIR\n",
    "\n",
    "for root, dirs, files in walklevel(CUR_PATH): \n",
    "    ### 6 Houses\n",
    "    for house in dirs:\n",
    "        house_number = int(house.split(' ')[1])\n",
    "        print('...' + house + '...')\n",
    "        CUR_PATH = change_path(house)\n",
    "        # read .txt file\n",
    "        for file in os.listdir(CUR_PATH):  \n",
    "            if fnmatch.fnmatch(file, '*.txt'):\n",
    "                with open(change_path(file)) as f:\n",
    "                    F = f.read()\n",
    "                    num_appliance_str = re.findall(r'[0-9][0-9]:\\s[^\\(]*[a-z]', F)\n",
    "                    dates = re.findall(r'[0-9][0-9]\\.[0-9][0-9]\\.[0-9][0-9]', F)\n",
    "            \n",
    "        # calculate data range from .txt file\n",
    "        start_date, end_date = swap_day_month(dates[2]), swap_day_month(dates[3]) #Plugs\n",
    "        # create the master df for the house\n",
    "        master_df = pd.DataFrame(pd.date_range(start=start_date, end=end_date, freq='S', closed='left'),\n",
    "                                 columns=['date']) #Plugs>Occupancy\n",
    "        ### Process Occupancy Data\n",
    "        if house_number != 6: # not available\n",
    "            print('Processing Occupancy Data...')\n",
    "            ROOT = CUR_PATH\n",
    "            CUR_PATH = change_path('Occupany') if house_number != 1 else change_path('Occupancy')\n",
    "\n",
    "            # read summer/winter.csv\n",
    "            csv_tuple = []\n",
    "            for file in os.listdir(CUR_PATH):  \n",
    "                if fnmatch.fnmatch(file, '*.csv'):\n",
    "                    csv_df = pd.read_csv(change_path(file), dtype=create_dtype_dict())\n",
    "                    # transpose csv_df\n",
    "                    csv_df = csv_df.set_index('Unnamed: 0')\n",
    "                    csv_df.index.name = ''\n",
    "                    csv_df = csv_df.T \n",
    "                    csv_tuple.append(csv_df)\n",
    "            assert csv_tuple[0].shape[0] == csv_tuple[1].shape[0]\n",
    "            combined_csv = pd.concat(csv_tuple, axis=1)       \n",
    "            # convert to 2 cols\n",
    "            combined_csv.index.name = 'date'\n",
    "            concat_lst = []\n",
    "            for col in combined_csv.columns:\n",
    "                df = combined_csv[col].to_frame()\n",
    "                df.rename(columns={col:'foo'}, inplace=True)\n",
    "                df.reset_index(level=0, inplace=True)\n",
    "                df['date'] = pd.date_range(start=col, periods=60*60*24, freq='S')\n",
    "                concat_lst.append(df)\n",
    "            # add to master_df\n",
    "            final_df = pd.concat(concat_lst).rename(columns={'foo':'occupancy'})\n",
    "            master_df = master_df.merge(final_df, on='date', how='left')\n",
    "            CUR_PATH = ROOT\n",
    "        \n",
    "        \n",
    "        \n",
    "        ### Process Plug Data\n",
    "        print('Processing Plugs Data...')\n",
    "        CUR_PATH = change_path('Plugs')\n",
    "        CUR_PATH = change_path('{:02}'.format(house_number))\n",
    "        ROOT = CUR_PATH\n",
    "        # get the names of the each electric appliance\n",
    "        num_appliance_dict = dict(item.split(\": \") for item in num_appliance_str)\n",
    "        # loop through each appliance\n",
    "        for n in num_appliance_dict.keys():\n",
    "            appliance_name = num_appliance_dict[n]\n",
    "            CUR_PATH = change_path(n)\n",
    "            concat_lst = []\n",
    "            # loop through each date of this appliance\n",
    "            done = [] # prevent duplicates from House 02/09\n",
    "            for file in os.listdir(CUR_PATH):  \n",
    "                if fnmatch.fnmatch(file, '*.csv'):\n",
    "                    date = swap_day_month2(os.path.splitext(file)[0][:10])\n",
    "                    if date in done:\n",
    "                        continue \n",
    "                    else:\n",
    "                        done.append(date)\n",
    "                    csv_df = pd.read_csv(change_path(file), names=[appliance_name])\n",
    "                    cur_df = pd.DataFrame(pd.date_range(start=date, periods=60*60*24, freq='S'), columns=['date'])\n",
    "                    cur_df[appliance_name] = csv_df.iloc[:,0]\n",
    "                    concat_lst.append(cur_df)\n",
    "            df = pd.concat(concat_lst, ignore_index=True)\n",
    "            master_df = master_df.merge(df, on='date', how='left')\n",
    "            CUR_PATH = ROOT\n",
    "                        \n",
    "        ### Process Metor Data (not now)\n",
    "        house_df_dict[house_number] = master_df\n",
    "        CUR_PATH = './DataSets'\n",
    "        print('Completed {}!'.format(house))\n",
    "print('Successfully merged all the data!!!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT = './DataSets'\n",
    "CUR_PATH = ROOT\n",
    "change_path = lambda DIR : CUR_PATH + '/' + DIR\n",
    "\n",
    "for root, dirs, files in walklevel(CUR_PATH):\n",
    "    ### 6 Houses\n",
    "    for house in dirs:\n",
    "        house_number = int(house.split(' ')[1])\n",
    "        print('...' + house + '...')\n",
    "        HOUSE_ROOT = change_path(house)\n",
    "        CUR_PATH = HOUSE_ROOT\n",
    "\n",
    "        if house_number != 6:\n",
    "            CUR_PATH = change_path('Occupany') if house_number != 1 else change_path('Occupancy')\n",
    "            for file in os.listdir(CUR_PATH)  :  \n",
    "                if fnmatch.fnmatch(file, '*.zip'):\n",
    "                    zip = zipfile.ZipFile(change_path(file), 'r')\n",
    "                    zip.extractall(CUR_PATH)\n",
    "                    print('unzipped ' + file + ' to ' + CUR_PATH)\n",
    "            CUR_PATH = HOUSE_ROOT\n",
    "\n",
    "        CUR_PATH = change_path('Plugs')\n",
    "        for file in os.listdir(CUR_PATH)  :  \n",
    "            if fnmatch.fnmatch(file, '*.zip'):\n",
    "                zip = zipfile.ZipFile(change_path(file), 'r')\n",
    "                zip.extractall(CUR_PATH)\n",
    "                print('unzipped ' + file + ' to ' + CUR_PATH)\n",
    "        CUR_PATH = ROOT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Check the created master DataFrames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in sorted(house_df_dict.keys()):\n",
    "    df = house_df_dict[key]\n",
    "    print('House {:02d} has {} millions of rows with the preview:'.format(key, round(df.shape[0]/1000000, 2)))\n",
    "    display(df.head())\n",
    "    print('Its features/columns are:')\n",
    "    print(*df.columns, sep=\", \") \n",
    "    print('')\n",
    "    print('The general data statistics are:')\n",
    "    display(df.describe())\n",
    "    print('The Data Frame information (null, data type, etc.) are:')\n",
    "    display(df.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Save the created DataFrames to files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for key in sorted(house_df_dict.keys()):\n",
    "    df = house_df_dict[key]\n",
    "    fname = 'house_{:02d}'.format(key, round(df.shape[0]/1000000, 2)) + '.csv'\n",
    "    df.to_csv(change_path(fname))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Clean the Data\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (a) Deal with `nan` and `-1` values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (b) ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Part 2: EDA\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Part 3: Time Series Spike\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Part 4: ML\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Part 5: Linear Programming\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
